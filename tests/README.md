# Test Suite for `dirdigest`

Welcome to the `dirdigest` test suite! This suite is designed to ensure the reliability, correctness, and robustness of the `dirdigest` command-line tool. We use `pytest` as our test runner and leverage various mock objects and fixtures to create isolated and repeatable test environments.

Our philosophy is to test thoroughly, from the command-line interface down to the core logic of file processing and output formatting. We believe that a strong test suite is the bedrock of a high-quality tool.

## Running the Tests

Running the tests is straightforward using the provided `Makefile`.

1.  **Ensure Development Dependencies are Installed:**
    Make sure you have set up the development environment and installed all dependencies, including `pytest`. If you followed the main project's [Development Setup](../README.md#development-setup) instructions (which uses `make setup`), these will already be installed in your virtual environment.
    ```bash
    # If you haven't already, from the project root:
    # make setup
    # source .venv/bin/activate
    ```

2.  **Run Tests using `make test` (Recommended):**
    From the root directory of the `dirdigest` project, simply run:
    ```bash
    make test
    ```
    This command will automatically:
    *   Execute the `tests/scripts/setup_test_dirs.sh` script to create mock directory fixtures.
    *   Run `pytest` on the `tests/` directory.
    *   Clean up the mock directory fixtures after the tests complete.

3.  **Running `pytest` Directly (Alternative):**
    If you need more granular control (e.g., running specific test files, using `pytest` flags like `-vv` for verbose output, or `-k` to select tests by keyword), you can run `pytest` directly.

    *   **First, manually set up the mock directory fixtures:**
        The test suite relies on pre-defined directory structures. A helper script is provided to create these:
        ```bash
        # From the root directory of the project
        bash tests/scripts/setup_test_dirs.sh
        ```
        It's recommended to run this script once before running `pytest` manually.

    *   **Then, run `pytest`:**
        Navigate to the root directory of the `dirdigest` project and run:
        ```bash
        pytest
        # or, using uv from the Makefile's venv:
        # uv run pytest tests/
        ```
        This will discover and run all tests within the `tests/` directory.

        To run a specific test file:
        ```bash
        pytest tests/test_cli_args.py
        ```

    *   **Remember to manually clean up fixtures if needed:**
        The mock directories are created in `tests/fixtures/test_dirs/`. The `make test` target handles cleanup. If running manually, you can remove this directory:
        ```bash
        rm -rf tests/fixtures/test_dirs
        ```

## Test Organization and Coverage

The tests are organized into several files, each focusing on a specific aspect of `dirdigest`:

*   **`tests/conftest.py`**:
    *   Contains shared `pytest` fixtures used across multiple test files.
    *   `runner`: Provides a `click.testing.CliRunner` instance to invoke CLI commands.
    *   `temp_test_dir`: Creates isolated temporary directories, populates them with mock file structures copied from the ones generated by `tests/scripts/setup_test_dirs.sh`, and manages CWD for tests.
    *   `mock_pyperclip`: Mocks the `pyperclip` library for testing clipboard functionality.

*   **`tests/test_cli_args.py`**:
    *   **Focus**: Command-Line Interface (CLI) argument parsing and basic invocation.
    *   **Coverage**: Help messages, version output, basic successful invocation, invalid arguments, parsing of options, clipboard flags.

*   **`tests/test_cli_sorting_and_logging.py`**:
    *   **Focus**: Verification of the detailed console log output, specifically its sorting behavior and formatting.
    *   **Coverage**: Default log sorting (status then size), various `--sort-output-log-by` scenarios (path-only, status then path, etc.), presence/absence of group headers ("EXCLUDED ITEMS", "INCLUDED ITEMS"), correct formatting of individual log lines (including item sizes and exclusion reasons), YAML configuration for sorting, and CLI override for sorting.

*   **`tests/test_configuration.py`**:
    *   **Focus**: Loading and merging settings from config files and CLI arguments.
    *   **Coverage**: Default/custom config files, CLI override precedence, YAML data types, config structures, malformed/missing files (including `sort_output_log_by` key).

*   **`tests/test_content_processing.py`**:
    *   **Focus**: How `dirdigest` handles file content after selection.
    *   **Coverage**: `--max-size`, empty files, file read errors (permission, Unicode) with/without `--ignore-errors`, UTF-8 handling.

*   **`tests/test_output_formatting.py`**:
    *   **Focus**: Validation of Markdown and JSON outputs, and unit tests for log formatting functions.
    *   **Coverage (Markdown)**: Header, directory structure visualization, file content sections, language hints, error representation.
    *   **Coverage (JSON)**: Metadata fields, `root` node structure.
    *   **Coverage (Log Formatting)**: Unit tests for `format_log_event_for_cli` ensuring correct string output for various log event data.

*   **`tests/test_traversal_filtering.py`**:
    *   **Focus**: Core file and directory traversal logic, and filtering mechanisms.
    *   **Coverage**: Basic traversal, default ignores, `--no-default-ignore`, hidden files, `--max-depth`, include/exclude patterns, symlink handling.

## Interpreting Test Outputs

When running tests, especially with verbose flags (`-v`, `-vv`), `dirdigest` may produce detailed console output. Key characteristics of this output to note:

*   **Verbose Processing Log:** When enabled (typically by tests passing `-v` or `--verbose`), a detailed log of processed files and folders is printed.
    *   **Format:** Each line includes the item's status (included/excluded), type (file/folder), relative path, reason for exclusion (if any), and its size in kilobytes (e.g., `(Size: 10.52KB)`).
    *   **Default Sorting:** This log is sorted by default: excluded items appear before included items. Within these groups, folders (by path) precede files (by size descending, then path).
    *   **Headers:** Group headers like "--- EXCLUDED ITEMS ---" and "--- INCLUDED ITEMS ---" are typically present unless sorting is by path only.
*   **Final Digest:** Tests may also capture and assert against the final digest output (Markdown or JSON), which is separate from the verbose processing log.

## Mock Fixtures (`tests/fixtures/test_dirs/`)

The test suite uses various pre-defined directory structures for testing. These structures are created by the `tests/scripts/setup_test_dirs.sh` script inside `tests/fixtures/test_dirs/`. The `make test` command runs this script automatically. If you run `pytest` directly, you should execute `bash tests/scripts/setup_test_dirs.sh` first.

These mock directories are designed to cover a wide range of scenarios:

*   `simple_project/`: A basic project with a few files and one subdirectory.
*   `complex_project/`: A more elaborate structure with nested directories, hidden files, default-ignored directories (like `.git`, `__pycache__`, `node_modules`), and various file types. Used to test default ignores, depth, and complex traversals.
*   `content_processing_dir/`: Contains files for testing content-related scenarios (sizes, UTF-8, binary, permissions).
*   `encoding_issues_dir/`: Contains files with non-UTF8 characters to test encoding error handling.
*   `hidden_files_dir/`: Specifically for testing handling of hidden files and files within hidden directories.
*   `lang_hint_project/`: Contains files with various extensions to test language hinting in Markdown.
*   `large_files_dir/`: Contains files of specific sizes to test `--max-size`.
*   `special_chars_dir/`: Contains files and directory names with spaces, special characters, and Unicode characters.
*   `symlink_dir/`: Contains target files/directories and various symbolic links (including a broken one) to test symlink handling logic.
